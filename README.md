## Pyspark_tutorial

PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment. PySpark supports most of Sparkâ€™s features such as Spark SQL, DataFrame, Streaming, MLlib (Machine Learning) and Spark Core.


![alt text](img/pyspark.png)

### Spark SQL and DataFrame
Spark SQL is a Spark module for structured data processing, in addition it provides programming abstraction called DataFrame
PySpark DataFrame From an Existing RDD
PySpark DataFrame From an External File



### MLlib
MLlib is a machine learning API in Apache Spark, it supports diffrent kind of algorithms:
* mllib.classification support various methods for binary classification, multiclass classification and regression analysis. 
* MLlib.regression Linear regression belongs to the family of regression algorithms
* mllib clustering : Clustering is an supervised learning problem, whereby using some notion of similarity you aim to group subsets of entities with one another 
* mllib.linalg MLlib utilities for linear algebra
* 

### Streaming 
the streaming feature in Apache Spark enables powerful interactive and analytical applications across both streaming and historical data.

### Spark Core
Spark Core is the underlying general execution engine for the Spark platform that all other functionality is built on top of. 